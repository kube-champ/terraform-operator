alertmanager:
  enabled: false

  config:
    global:
      resolve_timeout: 5m
      slack_api_url: https://hooks.slack.com/services/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

    route:
      group_by: ['alertname']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: slack
      routes: []

    receivers:
      - name: slack
        slack_configs:
        - channel: "#k8s-alert-manager-alerts"
          title: "{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}"
          text: "{{ range .Alerts }}{{ .Annotations.description }}\n{{ end }}"

    templates:
    - '/etc/alertmanager/config/*.tmpl'

additionalPrometheusRulesMap:
  terraform-operator:
    groups:
      - name: TerraformWorkflows
        rules:
          - alert: TerraformWorkflowFailed
            for: 5m
            expr: tfo_workflow_status == 1
            labels:
              severity: page
            annotations:
              summary: "terraform workflow \"{{ $labels.name }}\" failed"
              description: "workflow \"{{ $labels.namespace }}/{{ $labels.name }}\" failed for more than 5 minutes"
          - alert: TerraformWorkflowWaiting
            for: 30m
            expr: tfo_workflow_status == -1
            labels:
              severity: page
            annotations:
              summary: "terraform workflow \"{{ $labels.name }}\" still waiting"
              description: "workflow \"{{ $labels.namespace }}/{{ $labels.name }}\" is waiting for dependency for more than 30 minutes"

grafana:
  enabled: true

kubeStateMetrics:
  enabled: false

nodeExporter:
  enabled: false

kubeApiServer:
  enabled: false

kubelet:
  enabled: false

kubeControllerManager:
  enabled: false

coreDns:
  enabled: false

kubeEtcd:
  enabled: false

kubeScheduler:
  enabled: false

kubeProxy:
  enabled: false

prometheus:
  prometheusSpec:
    serviceMonitorSelector:
      matchLabels:
        app: terraform-operator